{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import RelationExtractor\n",
    "#from flair.datasets import RE_ENGLISH_DRUGPROT\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.embeddings import WordEmbeddings\n",
    "from torch.optim.adam import Adam\n",
    "from flair.datasets.relation_extraction import CoNLLUCorpus\n",
    "from flair.data import Corpus\n",
    "from flair.embeddings import FlairEmbeddings, TransformerWordEmbeddings\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair, torch\n",
    "flair.device = torch.device('cuda') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r'C:\\Users\\akumar33\\Documents\\RE_ALL\\RE_ALL'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair.__version__\n",
    "MAX_EPOCHS = 1\n",
    "lr = 0.01\n",
    "MODEL_PATH = r\"C:\\Users\\akumar33\\Documents\\RE_ALL\\RE_ALL\\RE_ALL\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# init embedding\n",
    "embedding_legalbert = TransformerWordEmbeddings( 'nlpaueb/legal-bert-base-uncased' , layers='-1', model_max_length=512, layer_mean=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open(os.path.join(DATA_PATH,TRAIN_FILE)) as file:\n",
    "    txt = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open(os.path.join(DATA_PATH,TEST_FILE)) as file:\n",
    "    txt = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open(os.path.join(DATA_PATH,DEV_FILE)) as file:\n",
    "    txt = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = txt.split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6958272"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\akumar33\\Documents\\RE_ALL\\RE_ALL\\dev.txt\", \"a\", encoding='utf8') as file:\n",
    "    file.truncate(0)\n",
    "    var2= txt.split('\\n\\n') \n",
    "    for i in var2:\n",
    "        seg = (i.split('\\n'))\n",
    "        for j in seg:\n",
    "\n",
    "            if 'relations' in j:\n",
    "                if ';' in j:\n",
    "                    file.write(i+'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\akumar33\\Documents\\RE_ALL\\RE_ALL\\dev_ner.txt\", \"a\", encoding='utf8') as file:\n",
    "    file.truncate(0)\n",
    "    var2= txt.split('\\n\\n') \n",
    "    for i in var2:\n",
    "        seg = (i.split('\\n'))\n",
    "        for j in seg:\n",
    "\n",
    "            if '#' not in j:\n",
    "                file.write(j+'\\n')\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\akumar33\\Documents\\RE_ALL\\RE_ALL\\train_ner.txt\", \"a\", encoding='utf8') as file:\n",
    "    file.truncate(0)\n",
    "    var2= txt.split('\\n\\n') \n",
    "    for i in var2:\n",
    "        seg = (i.split('\\n'))\n",
    "        for j in seg:\n",
    "\n",
    "            if '#' not in j:\n",
    "                file.write(j+'\\n')\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\akumar33\\Documents\\RE_ALL\\RE_ALL\\train.txt\", \"a\", encoding='utf8') as file:\n",
    "var= txt.split('\\n')    \n",
    "for i in range(len(var)):\n",
    "    if 'relations' in var[i]:\n",
    "        \n",
    "        if ';' not in var[i]:\n",
    "\n",
    "            print(var[i], var[i-1], var[i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RelationExtractor(\n",
       "  (loss_function): CrossEntropyLoss()\n",
       "  (token_embeddings): TransformerWordEmbeddings(\n",
       "    (model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (decoder): Linear(in_features=3072, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['state_dict', 'token_embeddings', 'label_dictionary', 'label_type', 'span_label_type', 'loss_weights', 'pooling_operation', 'dropout_value', 'use_entity_pairs'])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier._get_state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "# from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from flair.datasets import ColumnCorpus\n",
    "from flair.data import Corpus\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.data import Corpus \n",
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "from flair.embeddings import TokenEmbeddings\n",
    "\n",
    "from flair.embeddings import WordEmbeddings\n",
    "\n",
    "from flair.embeddings import StackedEmbeddings\n",
    "\n",
    "from flair.embeddings import FlairEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r'C:\\Users\\akumar33\\Documents\\RE_ALL\\RE_ALL'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = r\"C:\\Users\\akumar33\\Documents\\RE_ALL\\RE_ALL\\ner_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_legalbert = TransformerWordEmbeddings( 'nlpaueb/legal-bert-base-uncased' , layers='-1', model_max_length=512, layer_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-30 04:59:19,137 Reading data from C:\\Users\\akumar33\\Documents\\RE_ALL\\RE_ALL\n",
      "2021-11-30 04:59:19,138 Train: C:\\Users\\akumar33\\Documents\\RE_ALL\\RE_ALL\\train_ner.txt\n",
      "2021-11-30 04:59:19,139 Dev: C:\\Users\\akumar33\\Documents\\RE_ALL\\RE_ALL\\dev_ner.txt\n",
      "2021-11-30 04:59:19,140 Test: C:\\Users\\akumar33\\Documents\\RE_ALL\\RE_ALL\\test_ner.txt\n",
      "Dictionary with 17 tags: O, B-employmentTitle, I-employmentTitle, B-attorney, I-attorney, B-litigantRole, I-litigantRole, B-lawFirm, I-lawFirm, B-city, B-state, I-state, I-city, B-litigant, I-litigant, <START>, <STOP>\n",
      "2021-11-30 04:59:25,969 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-30 04:59:25,972 Model: \"SequenceTagger(\n",
      "  (embeddings): TransformerWordEmbeddings(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (rnn): LSTM(768, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=17, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-11-30 04:59:25,973 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-30 04:59:25,974 Corpus: \"Corpus: 6144 train + 2048 dev + 2048 test sentences\"\n",
      "2021-11-30 04:59:25,975 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-30 04:59:25,976 Parameters:\n",
      "2021-11-30 04:59:25,977  - learning_rate: \"0.1\"\n",
      "2021-11-30 04:59:25,978  - mini_batch_size: \"64\"\n",
      "2021-11-30 04:59:25,980  - patience: \"3\"\n",
      "2021-11-30 04:59:25,982  - anneal_factor: \"0.5\"\n",
      "2021-11-30 04:59:25,984  - max_epochs: \"5\"\n",
      "2021-11-30 04:59:25,986  - shuffle: \"True\"\n",
      "2021-11-30 04:59:25,988  - train_with_dev: \"True\"\n",
      "2021-11-30 04:59:25,988  - batch_growth_annealing: \"False\"\n",
      "2021-11-30 04:59:25,989 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-30 04:59:25,989 Model training base path: \"C:\\Users\\akumar33\\Documents\\RE_ALL\\RE_ALL\\ner_model\"\n",
      "2021-11-30 04:59:25,990 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-30 04:59:25,991 Device: cuda\n",
      "2021-11-30 04:59:25,991 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-30 04:59:25,992 Embeddings storage mode: gpu\n",
      "2021-11-30 04:59:25,998 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-30 05:00:03,750 epoch 1 - iter 12/128 - loss 2.25861627 - samples/sec: 109.99 - lr: 0.100000\n",
      "2021-11-30 05:00:10,478 epoch 1 - iter 24/128 - loss 1.79711178 - samples/sec: 120.47 - lr: 0.100000\n",
      "2021-11-30 05:00:17,521 epoch 1 - iter 36/128 - loss 1.73450154 - samples/sec: 123.59 - lr: 0.100000\n",
      "2021-11-30 05:00:26,356 epoch 1 - iter 48/128 - loss 1.60607350 - samples/sec: 92.17 - lr: 0.100000\n",
      "2021-11-30 05:00:37,317 epoch 1 - iter 60/128 - loss 1.40443013 - samples/sec: 76.90 - lr: 0.100000\n",
      "2021-11-30 05:00:44,400 epoch 1 - iter 72/128 - loss 1.34519714 - samples/sec: 115.18 - lr: 0.100000\n",
      "2021-11-30 05:00:53,114 epoch 1 - iter 84/128 - loss 1.27151776 - samples/sec: 99.12 - lr: 0.100000\n",
      "2021-11-30 05:01:02,106 epoch 1 - iter 96/128 - loss 1.16426548 - samples/sec: 95.08 - lr: 0.100000\n",
      "2021-11-30 05:01:09,261 epoch 1 - iter 108/128 - loss 1.10527977 - samples/sec: 117.84 - lr: 0.100000\n",
      "2021-11-30 05:01:18,638 epoch 1 - iter 120/128 - loss 1.04491836 - samples/sec: 91.29 - lr: 0.100000\n",
      "2021-11-30 05:01:25,518 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-30 05:01:25,519 EPOCH 1 done: loss 1.0044 - lr 0.1000000\n",
      "2021-11-30 05:04:46,851 TEST : loss 0.3441810607910156 - f1-score (micro avg)  0.7444\n",
      "2021-11-30 05:04:48,139 BAD EPOCHS (no improvement): 0\n",
      "2021-11-30 05:04:49,425 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-30 05:05:27,427 epoch 2 - iter 12/128 - loss 0.42338225 - samples/sec: 81.26 - lr: 0.100000\n",
      "2021-11-30 05:05:39,290 epoch 2 - iter 24/128 - loss 0.41058847 - samples/sec: 69.63 - lr: 0.100000\n",
      "2021-11-30 05:05:51,280 epoch 2 - iter 36/128 - loss 0.39121752 - samples/sec: 69.05 - lr: 0.100000\n",
      "2021-11-30 05:06:02,454 epoch 2 - iter 48/128 - loss 0.37760892 - samples/sec: 74.14 - lr: 0.100000\n",
      "2021-11-30 05:06:12,065 epoch 2 - iter 60/128 - loss 0.36069134 - samples/sec: 85.17 - lr: 0.100000\n",
      "2021-11-30 05:06:23,391 epoch 2 - iter 72/128 - loss 0.34504876 - samples/sec: 73.11 - lr: 0.100000\n",
      "2021-11-30 05:06:33,915 epoch 2 - iter 84/128 - loss 0.32981320 - samples/sec: 77.82 - lr: 0.100000\n",
      "2021-11-30 05:06:45,911 epoch 2 - iter 96/128 - loss 0.31689974 - samples/sec: 67.45 - lr: 0.100000\n",
      "2021-11-30 05:06:57,066 epoch 2 - iter 108/128 - loss 0.30629584 - samples/sec: 72.95 - lr: 0.100000\n",
      "2021-11-30 05:07:08,717 epoch 2 - iter 120/128 - loss 0.29573418 - samples/sec: 69.59 - lr: 0.100000\n",
      "2021-11-30 05:07:17,450 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-30 05:07:17,452 EPOCH 2 done: loss 0.2881 - lr 0.1000000\n",
      "2021-11-30 05:10:13,042 TEST : loss 0.07992783188819885 - f1-score (micro avg)  0.9367\n",
      "2021-11-30 05:10:14,114 BAD EPOCHS (no improvement): 0\n",
      "2021-11-30 05:10:15,346 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-30 05:10:54,558 epoch 3 - iter 12/128 - loss 0.17135238 - samples/sec: 67.10 - lr: 0.100000\n",
      "2021-11-30 05:11:04,597 epoch 3 - iter 24/128 - loss 0.17661461 - samples/sec: 83.39 - lr: 0.100000\n",
      "2021-11-30 05:11:16,356 epoch 3 - iter 36/128 - loss 0.16619574 - samples/sec: 70.12 - lr: 0.100000\n",
      "2021-11-30 05:11:27,295 epoch 3 - iter 48/128 - loss 0.16158370 - samples/sec: 72.92 - lr: 0.100000\n",
      "2021-11-30 05:11:38,092 epoch 3 - iter 60/128 - loss 0.15700021 - samples/sec: 76.95 - lr: 0.100000\n",
      "2021-11-30 05:11:48,734 epoch 3 - iter 72/128 - loss 0.15282062 - samples/sec: 76.45 - lr: 0.100000\n",
      "2021-11-30 05:11:59,696 epoch 3 - iter 84/128 - loss 0.14847757 - samples/sec: 75.54 - lr: 0.100000\n",
      "2021-11-30 05:12:11,873 epoch 3 - iter 96/128 - loss 0.14389391 - samples/sec: 67.63 - lr: 0.100000\n",
      "2021-11-30 05:12:23,636 epoch 3 - iter 108/128 - loss 0.14001781 - samples/sec: 68.79 - lr: 0.100000\n",
      "2021-11-30 05:12:34,909 epoch 3 - iter 120/128 - loss 0.13785130 - samples/sec: 73.26 - lr: 0.100000\n",
      "2021-11-30 05:12:42,434 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-30 05:12:42,435 EPOCH 3 done: loss 0.1358 - lr 0.1000000\n",
      "2021-11-30 05:15:38,393 TEST : loss 0.0421297661960125 - f1-score (micro avg)  0.962\n",
      "2021-11-30 05:15:39,690 BAD EPOCHS (no improvement): 0\n",
      "2021-11-30 05:15:40,911 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-30 05:16:18,699 epoch 4 - iter 12/128 - loss 0.09746393 - samples/sec: 75.52 - lr: 0.100000\n",
      "2021-11-30 05:16:29,820 epoch 4 - iter 24/128 - loss 0.09291340 - samples/sec: 72.75 - lr: 0.100000\n",
      "2021-11-30 05:16:41,096 epoch 4 - iter 36/128 - loss 0.09173791 - samples/sec: 73.27 - lr: 0.100000\n",
      "2021-11-30 05:16:53,056 epoch 4 - iter 48/128 - loss 0.09076986 - samples/sec: 67.54 - lr: 0.100000\n",
      "2021-11-30 05:17:03,321 epoch 4 - iter 60/128 - loss 0.09015489 - samples/sec: 81.62 - lr: 0.100000\n",
      "2021-11-30 05:17:14,343 epoch 4 - iter 72/128 - loss 0.09011036 - samples/sec: 74.03 - lr: 0.100000\n",
      "2021-11-30 05:17:24,761 epoch 4 - iter 84/128 - loss 0.08913592 - samples/sec: 80.48 - lr: 0.100000\n",
      "2021-11-30 05:17:37,531 epoch 4 - iter 96/128 - loss 0.08668354 - samples/sec: 64.59 - lr: 0.100000\n",
      "2021-11-30 05:17:48,812 epoch 4 - iter 108/128 - loss 0.08518893 - samples/sec: 71.82 - lr: 0.100000\n",
      "2021-11-30 05:18:00,300 epoch 4 - iter 120/128 - loss 0.08333557 - samples/sec: 72.40 - lr: 0.100000\n",
      "2021-11-30 05:18:08,248 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-30 05:18:08,249 EPOCH 4 done: loss 0.0819 - lr 0.1000000\n",
      "2021-11-30 05:21:03,823 TEST : loss 0.01954815536737442 - f1-score (micro avg)  0.9796\n",
      "2021-11-30 05:21:05,186 BAD EPOCHS (no improvement): 0\n",
      "2021-11-30 05:21:06,390 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-30 05:21:45,151 epoch 5 - iter 12/128 - loss 0.06036516 - samples/sec: 70.94 - lr: 0.100000\n",
      "2021-11-30 05:21:55,761 epoch 5 - iter 24/128 - loss 0.06259169 - samples/sec: 78.49 - lr: 0.100000\n",
      "2021-11-30 05:22:06,287 epoch 5 - iter 36/128 - loss 0.06105350 - samples/sec: 77.93 - lr: 0.100000\n",
      "2021-11-30 05:22:17,396 epoch 5 - iter 48/128 - loss 0.06073168 - samples/sec: 73.19 - lr: 0.100000\n",
      "2021-11-30 05:22:28,997 epoch 5 - iter 60/128 - loss 0.05901048 - samples/sec: 71.23 - lr: 0.100000\n",
      "2021-11-30 05:22:39,960 epoch 5 - iter 72/128 - loss 0.05766209 - samples/sec: 75.90 - lr: 0.100000\n",
      "2021-11-30 05:22:50,640 epoch 5 - iter 84/128 - loss 0.05647115 - samples/sec: 78.44 - lr: 0.100000\n",
      "2021-11-30 05:23:02,659 epoch 5 - iter 96/128 - loss 0.05527562 - samples/sec: 67.43 - lr: 0.100000\n",
      "2021-11-30 05:23:13,864 epoch 5 - iter 108/128 - loss 0.05423717 - samples/sec: 72.36 - lr: 0.100000\n",
      "2021-11-30 05:23:25,077 epoch 5 - iter 120/128 - loss 0.05340982 - samples/sec: 73.71 - lr: 0.100000\n",
      "2021-11-30 05:23:33,188 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-30 05:23:33,189 EPOCH 5 done: loss 0.0532 - lr 0.1000000\n",
      "2021-11-30 05:26:29,721 TEST : loss 0.014696314930915833 - f1-score (micro avg)  0.9852\n",
      "2021-11-30 05:26:30,968 BAD EPOCHS (no improvement): 0\n",
      "2021-11-30 05:26:33,354 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-30 05:26:33,356 Testing using last state of model ...\n",
      "2021-11-30 05:27:25,745 0.9839\t0.9865\t0.9852\t0.9731\n",
      "2021-11-30 05:27:25,747 \n",
      "Results:\n",
      "- F-score (micro) 0.9852\n",
      "- F-score (macro) 0.9529\n",
      "- Accuracy 0.9731\n",
      "\n",
      "By class:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       attorney     0.9808    0.9928    0.9867      4416\n",
      "          state     0.9876    0.9996    0.9935      2224\n",
      "           city     0.9915    0.9955    0.9935      2224\n",
      "   litigantRole     0.9746    0.9868    0.9807      1824\n",
      "        lawFirm     0.9928    0.9770    0.9848      1824\n",
      "employmentTitle     0.9965    0.9965    0.9965      1728\n",
      "       litigant     0.8238    0.6625    0.7344       240\n",
      "\n",
      "      micro avg     0.9839    0.9865    0.9852     14480\n",
      "      macro avg     0.9639    0.9444    0.9529     14480\n",
      "   weighted avg     0.9835    0.9865    0.9848     14480\n",
      "    samples avg     0.9731    0.9731    0.9731     14480\n",
      "\n",
      "2021-11-30 05:27:25,749 ----------------------------------------------------------------------------------------------------\n",
      "G18_G13_G6_G27_G9_G14_G28_G1_G20_G15_G11_G12_G10_G17_G2_G4_G5_G25_G22_G23_G24_G8 : COMPLETED MODEL TRAINING FOR THIS GROUP\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "##THIS CELL IS USED FOR NER TRAIN WITH FILE TRAIN_NER, TEST_NER\n",
    "\n",
    "# tag_dictionary.add_unk = True # To handle unknown tags, such as 5-attor\n",
    "TRAIN_FILE = f'train_ner.txt'\n",
    "TEST_FILE = f'test_ner.txt'\n",
    "DEV_FILE = f'dev_ner.txt'    \n",
    "\n",
    "\n",
    "# Define corpus for each group\n",
    "COLUMNS = {0:'id', 1: 'text', 2:'ner'}\n",
    "\n",
    "#Load the corpus for each group \n",
    "corpus: Corpus =ColumnCorpus(DATA_PATH, COLUMNS,\n",
    "                            train_file=TRAIN_FILE,\n",
    "                            test_file=TEST_FILE,\n",
    "                            dev_file=DEV_FILE,\n",
    "                            in_memory= False\n",
    "                            )\n",
    "#Create pletionary\n",
    "# new tags of new corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type='ner')\n",
    "\n",
    "tag_dictionary.add_item('O')\n",
    "print(tag_dictionary)\n",
    "# initialize new tagger with extended dictionary (re-use same embeddings as before)\n",
    "tagger: SequenceTagger = SequenceTagger(\n",
    "        hidden_size=256,\n",
    "        embeddings=embedding_legalbert,\n",
    "        tag_dictionary=tag_dictionary,\n",
    "        tag_type='ner',\n",
    "    )\n",
    "\n",
    "#Define the model\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "trainer.train(MODEL_PATH, learning_rate=0.1,\n",
    "                mini_batch_size=64,\n",
    "                max_epochs=5, \n",
    "                monitor_train=True,\n",
    "                monitor_test=True,\n",
    "                checkpoint=True, \n",
    "                train_with_dev=True,\n",
    "                embeddings_storage_mode= \"gpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-employmentTitle',\n",
       " 'I-employmentTitle',\n",
       " 'B-attorney',\n",
       " 'I-attorney',\n",
       " 'B-litigantRole',\n",
       " 'I-litigantRole',\n",
       " 'B-lawFirm',\n",
       " 'I-lawFirm',\n",
       " 'B-city',\n",
       " 'B-state',\n",
       " 'I-state',\n",
       " 'I-city',\n",
       " 'B-litigant',\n",
       " 'I-litigant',\n",
       " '<START>',\n",
       " '<STOP>']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_dictionary.get_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
